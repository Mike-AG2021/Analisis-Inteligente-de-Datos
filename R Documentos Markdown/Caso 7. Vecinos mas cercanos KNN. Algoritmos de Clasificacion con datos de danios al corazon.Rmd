---
title: Caso 7. Vecinos mas cercanos KNN. Algoritmos de Clasificacion con datos de
  daños al corazon
author: Jesús Miguel Acosta Gurrola
date: 05/05/2022
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 6
    number_sections: no
---

# **Objetivo**

Construir y evaluar un modelo *KNN* para resolver tarea de clasificación mediante la predicción de si una persona tiene daño de corazón o no.

# **Fundamento Teórico**

El método **K-NN** es un método importantes de clasificación supervisada. En el proceso de aprendizaje no se hace ninguna suposición acerca de la distribución de las variables predictoras, es por ello que es un método de clasificación no paramétrico, que estima el valor de la función de densidad de probabilidad o directamente la probabilidad posterior de que un elemento $x$ pertenezca a la clase $C_j$ a partir de la información proporcionada por el conjunto de entrenamiento.

Es un método bastante sencillo y robusto que simplemente busca en las observaciones más cercanas a la que se está tratando de predecir y clasifica el punto de interés basado en la mayoría de datos que le rodean.

Es un algoritmo muy simple de implementar y de entrenar, pero tienen una carga computacional elevada y **no es apropiado cuando se tienen muchos grados de libertad.** (Villalba 2018).

# **Descripción**

Cargar librerías, datos y hacer lo necesario aplicando función *knn* de la librería *class* y la función *train.knn* de la librería *kknn*.

Se descargan los datos: <https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/heart_2020_cleaned.csv>

Los datos están relacionados con aspectos médicos y son valores numéricos de varias variables que caracterizan el estado de salud de 319,795 personas.

Se pretende construir un modelo utilizando algoritmos supervisados para resolver la tarea de clasificación binaria e identificar si una persona padece del corazón o no.

Se construyen datos de entrenamiento y validación al 80% y 20% cada uno.

Se desarrollan los modelos de:

-   Regresión Logística binaria

-   Árbol de Clasificación tipo class

-   **K Means**

-   SVM Lineal

-   SVM Polinomial

-   SVM Radial

Los modelo se aceptan si tienen un valor de exactitud por encima del 70%.

# **Desarrollo**

## **Cargar librerías**

```{r message=FALSE, warning=FALSE}
library(readr) # Leer datos
library(kknn)  # KNN modelo para kknn
library(dplyr) # Procesar filtrar
library(forcats)   # para decodificar vars
library(class)     # Para knn()
library(caret)     # Matriz de confusión entre otros
library(reshape)   # Para modificar variables 
library(knitr)     # Para tablas amigables
```

## **Cargar datos**

Cargar datos de manera local.

```{r}
# datos <- read.csv("https://raw.githubusercontent.com/rpizarrog/Machine-Learning-con-R/main/datos/heart_2020_cleaned.csv")
datos <- read.csv("~/Documentos R Markdown/heart_2020_cleaned.csv", encoding = "UTF-8", stringsAsFactors = TRUE)
```

## **Explorar datos**

```{r}
str(datos)
```

```{r}
summary(datos)
```

## **Limpiar datos**

No es necesario alguna transformación

## **Las variables de interés**

Todas las variables son de entrada o variables independientes:

-   "BMI": Indice de masa corporal con valores entre 12.02 y 94.85.

-   "Smoking": Si la persona es fumadora o no con valores categóritos de 'Yes' o 'No.'

-   "AlcoholDrinking" : Si consume alcohol o no, con valores categóricos de 'Yes' o 'No.'

-   "Stroke": Si padece alguna anomalía cerebrovascular, apoplejia o algo similar, con valores categóricos de 'Yes' o 'No.'

-   "PhysicalHealth" Estado físico en lo general con valores entre 0 y 30.

-   "MentalHealth." Estado mental en lo general con valores entre 0 y 30.

-   "DiffWalking" . Que si se le dificulta caminar o tiene algún padecimiento al caminar, con valores categóritoc de 'Yes' o 'No.'

-   "Sex": Género de la persona, con valores de 'Female' y 'Male' para distinguir al género femenino y masculino respectivamente.

-   "AgeCategory": Una clasificación de la edad de la persona de entre 18 y 80 años. La primera categoría con un rango de edad entre 18-24, a partir de 25 con rangos de 5 en 5 hasta la clase de 75-80 y una última categoría mayores de 80 años.

-   "Race." Raza u origen de la persona con valores categóricos de '*American Indian/Alaskan Native', 'Asian','Black', 'Hispanic', 'Other'* y'*White'.*

-   "Diabetic." Si padece o ha padecido de diabetes en cuatro condiciones siendo Yes y No para si o no: 'No,' 'borderline diabetes' condición antes de detectarse diabetes tipo 2, 'Yes,' y 'Yes (during pregnancy)' durante embarazo.

-   "PhysicalActivity" que si realiza actividad física, con valores categóricos de 'Yes' o 'No.'

-   "GenHealth": EStado general de salud de la persona con valores categóricos de 'Excellent,' 'Very good,' 'Good,' 'Fair' y 'Poor' con significado en español de excelente, muy buena, buena, regular y pobre o deficiente.

-   "SleepTime": valor numérico de las horas de sueño u horas que duerme la persona con valores en un rango entre 1 y 24.

-   "Asthma": si padece de asma o no, con valores categóricos de 'Yes' o 'No.'

-   "KidneyDisease": si tiene algún padecimiento en los riñones, con valores categóricos de 'Yes' o 'No.'

-   "SkinCancer": si padece algún tipo de cancer de piel, con valores categóricos de 'Yes' o 'No.'

La variable de interés como dependiente o variable de salida es la de daño al corazón (HeartDisease), con valores categóricos de 'Yes' o 'No.'

## **Datos de entrenamiento y validación**

Se parten los datos en en datos de entrenamiento con el 80% y datos de validación con el 20%.

```{r}
set.seed(2022)
entrena <- createDataPartition(y = datos$HeartDisease, 
                               p = 0.8, 
                               list = FALSE, 
                               times = 1)

# Datos entrenamiento
datos.entrenamiento <- datos[entrena, ]  # [renglones, columna]

# Datos validación
datos.validacion <- datos[-entrena, ]
```

### **Datos de entrenamiento**

Se muestran los primeros 20 registros datos de entrenamiento

```{r}
kable(head(datos.entrenamiento, 20), caption = "Primeros 20 registros de datos de entrenamiento")
```

### **Datos de validación**

Se muestran los primeros 20 registros de datos de validación .

```{r}
kable(head(datos.entrenamiento, 20), caption = "Primeros 20 registros de datos de entrenamiento")
```

## **Construir un modelo KNN**

Construir el modelo bajo el algoritmo KNN en donde la variable *HeartDisease* depende de todos las variables.

Se construye el modelo con una muestra de *2000* mil observaciones en lugar de las 255837 que tienen el conjunto de datos de entrenamiento.

```{r}
muestra <- sample(x = 1:nrow(datos.entrenamiento), size = 10000, replace = FALSE)
```

Se construye el modelo..

```{r}
modelo.knnn <- train.kknn(data = datos.entrenamiento[muestra, ], formula = HeartDisease ~ ., kmax = 30)

summary(modelo.knnn)
```

## **Evaluar el modelo con los datos de validación**

```{r}
predicciones <- predict(object = modelo.knnn, newdata = datos.validacion)
```

### **Construir un data frame para comparar reales con predicciones**

Solo se observan los primeros 20 registros a comparar

```{r}
datos.comparar <- data.frame("real" = datos.validacion$HeartDisease, "predicho" = predicciones)

kable(head(datos.comparar, 20), caption = "Datos a comparar previo a matriz de confusión" )
```

### **Construyendo matriz de confusión**

Con la función *confussion* el estadístico Accuracy = Exactitud.

```{r}
matriz <- confusionMatrix(datos.comparar$real, datos.comparar$predicho)

matriz
```

Se tiene una Accuracy = exactitud del 91.30%

## **Mismo algoritmo pero con función knn**

### **Limpiar los datos**

Este proceso es transformar variables

Antes de utilizar este modelo debe convertirse los valores de las variables cualitativas tipo factor a variables numéricas. Primero las variable dicotómicas Yes, No a 1, 2.

Se construye un *data.frame* similar pero llamado *datos2* con variables numéricas en lugar de factores; esto se hace para el modelo se construya con la función *knn()*.

#### **Smoking, AlcoholDrinking, Stroke, DiffWalking, Sex PhysicalActivity, Asthma, KidneyDisease, SkinCance**

```{r}
datos2 <- datos %>%
  mutate(Smoking = if_else(Smoking == 'Yes', 1, 2), AlcoholDrinking = if_else(AlcoholDrinking == 'Yes', 1, 2), Stroke = if_else(Stroke == 'Yes', 1, 2), DiffWalking = if_else(DiffWalking == 'Yes', 1, 2), Sex = if_else(Sex == 'Female', 1, 2), PhysicalActivity = if_else(PhysicalActivity == 'Yes', 1, 2), Asthma = if_else(Asthma == 'Yes', 1, 2), KidneyDisease = if_else(KidneyDisease == 'Yes', 1, 2), SkinCancer = if_else(SkinCancer == 'Yes', 1, 2))
```

#### **AgeCategory**

```{r}
datos2 <- datos2 %>%
  mutate(AgeCategory = ifelse (AgeCategory == '18-24',  1, ifelse(AgeCategory == '25-29', 2, ifelse(AgeCategory == '30-34', 3, ifelse(AgeCategory == '35-39', 4, ifelse(AgeCategory == '40-44', 5, ifelse(AgeCategory == '45-49', 6, ifelse(AgeCategory == '50-54', 7, ifelse(AgeCategory == '55-59', 8, ifelse(AgeCategory == '60-64', 9, ifelse(AgeCategory == '65-69', 10, ifelse(AgeCategory == '70-74', 11, ifelse(AgeCategory == '75-79', 12, 13)))))))))))))
```

#### **Race**

```{r}
datos2 <- datos2 %>%
  mutate(Race = ifelse (Race == 'White',  1, ifelse(Race == 'Black', 2, ifelse(Race == 'Asian', 3, ifelse(Race == 'American Indian/Alaskan Native', 4, ifelse(Race == 'Other', 5, 6 ))))))
```

#### **Diabetic**

```{r}
datos2 <- datos2 %>%
  mutate(Diabetic = ifelse (Diabetic == 'Yes',  1, ifelse(Diabetic == 'No', 2, ifelse(Diabetic == 'No, borderline diabetes', 3, 4))))
```

#### **GenHealth**

```{r}
datos2 <- datos2 %>%
  mutate(GenHealth = ifelse (Race == 'Fair',  1, ifelse(GenHealth == 'Poor', 2, ifelse(GenHealth == 'Good', 3, ifelse(GenHealth == 'Very good', 4, 5 )))))
```

### **Datos de entrenamiento y validación**

Nuevamente partir en datos de entrenamiento y validación per ahora con los datos2

```{r}
set.seed(2022)
entrena <- createDataPartition(y = datos2$HeartDisease, 
                               p = 0.8, 
                               list = FALSE, 
                               times = 1)

# Datos entrenamiento
datos.entrenamiento <- datos2[entrena, ]  # [renglones, columna]

# Datos validación
datos.validacion <- datos2[-entrena, ]
```

Nuevamente una muestra de los datos de entrenamento.

```{r}
muestra <- sample(x = 1:nrow(datos.entrenamiento), size = 10000, replace = FALSE)

```

### **Construir el modelo knn**

Se utiliza la función *knn* de la librería *class* para estimar predicciones. Se utiliza la variable predicciones.2 para diferenciar de la variable predicciones.

Se utiliza una muestra de 10000 mil registros de los datos de entrenamiento porque el modelo se tarda bastante tiempo en construirse si se utilian todos los registros de los datos de entrenamiento.

```{r}
# predicciones.2 <- knn(train = datos.entrenamiento[, -1], test = datos.validacion[, -1], cl = datos.entrenamiento[,1], k = 12)

predicciones.2 <- knn(train = datos.entrenamiento[muestra, -1], test = datos.validacion[, -1], cl = datos.entrenamiento[muestra,1], k = 12)
```

### **Matriz de confusión**

Determinando la matriz de confusión con predicciones.2

```{r}
matriz2 <- confusionMatrix(datos.validacion$HeartDisease, predicciones.2)
matriz2
```

## **Interpretación**

El modelo KNN con la función train.kknn() arroja una exactitud del 91.30%, significa que el modelo acierta en 91.30% ocasiones de cada cien pacientes.

El modelo KNN con la función knn() arroja una exactitud del 91.37%, significa que el modelo acierta en 91.37 ocasiones de cada cien pacientes.

Siendo el mismo algoritmo las funciones mismas arrojan diferentes estadísticos. Esto supone el algoritmo es diferente el código de cada función ya que cada una de ellas encapsula su propio código dependiendo del paquete y del autor.

En este caso hicimos el analisis de datos con algoritmos de clasificación, fue con el mism algoritmo pero con la funcion de knn, y las predicciones con los procesos para transformar variables, basados en tareas de clasificación de datos.

Los datos que están relacionados con aspectos médicos y con valores numéricos de varias variables se caracterizan por el estado de salud que es de los mismos datos que el analisis del caso anterior 319,795 personas. Al cual se le realizo este análisis estadístico.

Se puede comparar contra otros modelos anteriores.

**Bibliografía**
Villalba, F. 2018. "Aprendizaje Supervisado En r," October. <https://fervilber.github.io/Aprendizaje-supervisado-en-R/>.




































